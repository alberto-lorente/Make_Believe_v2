{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>total_n_ents</th>\n",
       "      <th>n_org_ents</th>\n",
       "      <th>n_per_ents</th>\n",
       "      <th>n_gpe_ents</th>\n",
       "      <th>n_norp_ents</th>\n",
       "      <th>n_date_ents</th>\n",
       "      <th>entities</th>\n",
       "      <th>org_ents</th>\n",
       "      <th>per_ents</th>\n",
       "      <th>gpe_ents</th>\n",
       "      <th>norp_ents</th>\n",
       "      <th>date_ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathyU.S...</td>\n",
       "      <td>True</td>\n",
       "      <td>495</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>['Kerry', 'Paris', 'State', 'John F. Kerry', '...</td>\n",
       "      <td>['State', 'the American Embassy']</td>\n",
       "      <td>['Kerry', 'John F. Kerry', 'Kerry', 'Laurent F...</td>\n",
       "      <td>['Paris', 'Paris', 'Paris', 'France', 'Sofia',...</td>\n",
       "      <td>['American', 'French', 'Israeli', 'European', ...</td>\n",
       "      <td>['Monday', 'later this week', 'Sunday', 'Thurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>True</td>\n",
       "      <td>405</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>['New York', 'Hillary Clinton', 'Donald Trump'...</td>\n",
       "      <td>['Trump', 'the White House', 'Trump', 'Sanders...</td>\n",
       "      <td>['Hillary Clinton', 'Donald Trump', 'Ted Cruz'...</td>\n",
       "      <td>['New York', 'Ohio', 'New York', 'New York', '...</td>\n",
       "      <td>['Republican', 'Republican', 'Democratic', 'In...</td>\n",
       "      <td>['year', 'this weekend', 'November']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106A Czech stock...</td>\n",
       "      <td>True</td>\n",
       "      <td>148</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>['Britain', 'Schindler’ Dies', 'Czech', 'Jewis...</td>\n",
       "      <td>['Schindler’ Dies', 'Winton', 'Winton', 'Winton']</td>\n",
       "      <td>['Dubbed “Britain’s Schindler', 'Nicholas Wint...</td>\n",
       "      <td>['Britain', 'Nazi Germany', 'Prague', 'Germany...</td>\n",
       "      <td>['Czech', 'Jewish', 'Jewish', 'German']</td>\n",
       "      <td>['the age of 106', 'March 1939', '2003', 'near...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>True</td>\n",
       "      <td>2861</td>\n",
       "      <td>298</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>['Trump', 'Clinton', 'Clinton', 'Donald Trump'...</td>\n",
       "      <td>['Trump', 'NBC', 'Trump', 'Obama', 'Trump', 't...</td>\n",
       "      <td>['Clinton', 'Clinton', 'Donald Trump', '• Clin...</td>\n",
       "      <td>['Iraq', 'Iraq', 'Obama', 'China', 'Saudi Arab...</td>\n",
       "      <td>['Republicans', 'Democratic', 'Republicans', '...</td>\n",
       "      <td>['Sept. 7', 'Today', 'Sept. 11, 2002', 'about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>True</td>\n",
       "      <td>813</td>\n",
       "      <td>77</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>['Iran', 'U.S.', 'Iran', 'the final days', 'Th...</td>\n",
       "      <td>['The New York Times', 'Times', 'The Associate...</td>\n",
       "      <td>['Olli Heinonen', 'John Kerry', 'Edward Kenned...</td>\n",
       "      <td>['Iran', 'U.S.', 'Iran', 'Tehran', 'Russia', '...</td>\n",
       "      <td>['Western', 'French', 'German', 'Iranian']</td>\n",
       "      <td>['the final days', 'late Sunday', 'just two da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text polarity  n_tokens  \\\n",
       "0  Kerry to go to Paris in gesture of sympathyU.S...     True       495   \n",
       "1  The Battle of New York: Why This Primary Matte...     True       405   \n",
       "2  ‘Britain’s Schindler’ Dies at 106A Czech stock...     True       148   \n",
       "3  Fact check: Trump and Clinton at the 'commande...     True      2861   \n",
       "4  Iran reportedly makes new push for uranium con...     True       813   \n",
       "\n",
       "   total_n_ents  n_org_ents  n_per_ents  n_gpe_ents  n_norp_ents  n_date_ents  \\\n",
       "0            58           2          17          23            6           10   \n",
       "1            42          12          14           9            4            3   \n",
       "2            24           4           4           8            4            4   \n",
       "3           298         103          87          60           12           36   \n",
       "4            77          12           7          39            4           15   \n",
       "\n",
       "                                            entities  \\\n",
       "0  ['Kerry', 'Paris', 'State', 'John F. Kerry', '...   \n",
       "1  ['New York', 'Hillary Clinton', 'Donald Trump'...   \n",
       "2  ['Britain', 'Schindler’ Dies', 'Czech', 'Jewis...   \n",
       "3  ['Trump', 'Clinton', 'Clinton', 'Donald Trump'...   \n",
       "4  ['Iran', 'U.S.', 'Iran', 'the final days', 'Th...   \n",
       "\n",
       "                                            org_ents  \\\n",
       "0                  ['State', 'the American Embassy']   \n",
       "1  ['Trump', 'the White House', 'Trump', 'Sanders...   \n",
       "2  ['Schindler’ Dies', 'Winton', 'Winton', 'Winton']   \n",
       "3  ['Trump', 'NBC', 'Trump', 'Obama', 'Trump', 't...   \n",
       "4  ['The New York Times', 'Times', 'The Associate...   \n",
       "\n",
       "                                            per_ents  \\\n",
       "0  ['Kerry', 'John F. Kerry', 'Kerry', 'Laurent F...   \n",
       "1  ['Hillary Clinton', 'Donald Trump', 'Ted Cruz'...   \n",
       "2  ['Dubbed “Britain’s Schindler', 'Nicholas Wint...   \n",
       "3  ['Clinton', 'Clinton', 'Donald Trump', '• Clin...   \n",
       "4  ['Olli Heinonen', 'John Kerry', 'Edward Kenned...   \n",
       "\n",
       "                                            gpe_ents  \\\n",
       "0  ['Paris', 'Paris', 'Paris', 'France', 'Sofia',...   \n",
       "1  ['New York', 'Ohio', 'New York', 'New York', '...   \n",
       "2  ['Britain', 'Nazi Germany', 'Prague', 'Germany...   \n",
       "3  ['Iraq', 'Iraq', 'Obama', 'China', 'Saudi Arab...   \n",
       "4  ['Iran', 'U.S.', 'Iran', 'Tehran', 'Russia', '...   \n",
       "\n",
       "                                           norp_ents  \\\n",
       "0  ['American', 'French', 'Israeli', 'European', ...   \n",
       "1  ['Republican', 'Republican', 'Democratic', 'In...   \n",
       "2            ['Czech', 'Jewish', 'Jewish', 'German']   \n",
       "3  ['Republicans', 'Democratic', 'Republicans', '...   \n",
       "4         ['Western', 'French', 'German', 'Iranian']   \n",
       "\n",
       "                                           date_ents  \n",
       "0  ['Monday', 'later this week', 'Sunday', 'Thurs...  \n",
       "1               ['year', 'this weekend', 'November']  \n",
       "2  ['the age of 106', 'March 1939', '2003', 'near...  \n",
       "3  ['Sept. 7', 'Today', 'Sept. 11, 2002', 'about ...  \n",
       "4  ['the final days', 'late Sunday', 'just two da...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Datasets/news_processed_spacy.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathyU.S...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106A Czech stock...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text polarity\n",
       "0  Kerry to go to Paris in gesture of sympathyU.S...     True\n",
       "1  The Battle of New York: Why This Primary Matte...     True\n",
       "2  ‘Britain’s Schindler’ Dies at 106A Czech stock...     True\n",
       "3  Fact check: Trump and Clinton at the 'commande...     True\n",
       "4  Iran reportedly makes new push for uranium con...     True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data [[\"text\", \"polarity\"]]\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_18568\\1242683664.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data_clean.replace({\"True\": 1, \"Fake\":0}, inplace=True)\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_18568\\1242683664.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean.replace({\"True\": 1, \"Fake\":0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_clean.replace({\"True\": 1, \"Fake\":0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "1    3171\n",
       "0    3164\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[\"polarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_indexes(number, percentage, df, used_indexes=False, used_indexes_2=False):\n",
    "    \n",
    "    \"\"\"Manually sampling the indexes of the dataframe taking into account the previously sampled indexes \n",
    "    \n",
    "    \"\"\"\n",
    "    possible_indexes = list(df.index)\n",
    "    \n",
    "    if used_indexes:\n",
    "        possible_indexes = [index for index in possible_indexes if index not in used_indexes]\n",
    "    if used_indexes_2:\n",
    "        possible_indexes = [index for index in possible_indexes if index not in used_indexes_2]\n",
    "    \n",
    "    df_sampleable = df[df.index.isin(possible_indexes)]\n",
    "    \n",
    "    n_samples = int(percentage*number)\n",
    "    df_sample = df_sampleable.sample(n_samples)\n",
    "    \n",
    "    return df_sample\n",
    "\n",
    "training_portion = data_clean.copy()\n",
    "testing_portion = data_clean.copy()\n",
    "validation_portion = data_clean.copy()\n",
    "\n",
    "def is_double(list_1, list_2, list_3):\n",
    "    same_index = list(set(list_1).intersection(set(list_2), set(list_3)))\n",
    "    if len(same_index) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "while is_double(list(training_portion.index), list(testing_portion.index), list(validation_portion.index)) == True:\n",
    "    training_portion = random_indexes(6335, 0.7, training_portion)\n",
    "    testing_portion = random_indexes(6335, 0.15, testing_portion, used_indexes = list(training_portion.index))\n",
    "    validation_portion = random_indexes(6335, 0.15, validation_portion, used_indexes = list(training_portion.index), used_indexes_2 = list(testing_portion.index))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_index = list(set(training_portion.index).intersection(set(testing_portion.index), set(validation_portion.index)))\n",
    "same_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the DataFrames into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'True': 1, 'Fake': 0}\n",
      "{1: 'True', 0: 'Fake'}\n"
     ]
    }
   ],
   "source": [
    "id2label = {\"True\": 1, \"Fake\":0}\n",
    "label2id = {value: key for key, value in id2label.items()}\n",
    "\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataloader = Dataset.from_pandas(training_portion)\n",
    "validation_dataloader = Dataset.from_pandas(validation_portion)\n",
    "test_dataloader = Dataset.from_pandas(testing_portion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'polarity', '__index_level_0__'],\n",
       "    num_rows: 4434\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'IF HILLARY CLINTON IS CHARGED WITH OBSTRUCTION OF JUSTICE SHE COULD GO TO PRISON FOR 20 YEARSHome › POLITICS › IF HILLARY CLINTON IS CHARGED WITH OBSTRUCTION OF JUSTICE SHE COULD GO TO PRISON FOR 20 YEARS IF HILLARY CLINTON IS CHARGED WITH OBSTRUCTION OF JUSTICE SHE COULD GO TO PRISON FOR 20 YEARS 0 SHARES \\n[10/31/16] MICHAEL SNYDER -In the world of politics, the cover-up is often worse than the original crime. It was his role in the Watergate cover-up that took down Richard Nixon, and now Hillary Clinton’s cover-up of her email scandal could send her to prison for a very, very long time. When news broke that the FBI has renewed its investigation into Hillary Clinton’s emails, it sent shockwaves throughout the political world . But this time around, we aren’t just talking about an investigation into the mishandling of classified documents. I haven’t heard anyone talking about this, but if the FBI discovers that Hillary Clinton altered, destroyed or concealed any emails that should have been turned over to the FBI during the original investigation, she could be charged with obstruction of justice. That would immediately end her political career, and if she was found guilty it could send her to prison for the rest of her life. \\nI have not seen a single news report mention the phrase “obstruction of justice” yet, but I am convinced that there is a very good chance that this is where this scandal is heading. The following is the relevant part of the federal statute that deals with obstruction of justice … \\nWhoever knowingly alters, destroys, mutilates, conceals, covers up, falsified, or makes a false entry in any record, document, or tangible object with the intent to impede, obstruct, or influence the investigation or proper administration of any matter within the jurisdiction of any department or agency of the United States or any case filed under Title 11, or in relation to or contemplation of any such matter or case, shall be fined under this title, imprisoned not more than 20 years, or both. \\nIf Hillary Clinton is sent to prison for 20 years, that would essentially be for the rest of her life. \\nI have a feeling that the FBI is going to find a great deal of evidence of obstruction of justice in Huma Abedin’s emails. But unfortunately there is not likely to be a resolution to this matter before November 8th, because according to the Wall Street Journal there are approximately 650,000 emails to search through… \\nAs federal agents prepare to scour roughly 650,000 emails to see how many relate to a prior probe of Hillary Clinton ’s email use, the surprise disclosure that investigators were pursuing the potential new evidence lays bare building tensions inside the bureau and the Justice Department over how to investigate the Democratic presidential nominee. \\nMetadata found on the laptop used by former Rep. Anthony Weiner and his estranged wife Huma Abedin, a close Clinton aide, suggests there may be thousands of emails sent to or from the private server that Mrs. Clinton used while she was secretary of state, according to people familiar with the matter. It will take weeks, at a minimum, to determine whether those messages are work-related from the time Ms. Abedin served with Mrs. Clinton at the State Department; how many are duplicates of emails already reviewed by the Federal Bureau of Investigation; and whether they include either classified information or important new evidence in the Clinton email probe. \\nOf those 650,000 emails, an inside source told Fox News that “ at least 10,000 ” would be of interest to the investigation. \\nAt this point, FBI officials have not even begun searching through the emails, because a search warrant has not been secured yet. The following comes from CNN … \\nGovernment lawyers haven’t yet approached Abedin’s lawyers to seek an agreement to conduct the search. Sources earlier told CNN that those discussions had begun, but the law enforcement officials now say they have not. \\nEither way, government lawyers plan to seek a search warrant from a judge to conduct the search of the computer, the law enforcement officials said. \\nBut the FBI is reportedly already searching a laptop that was co-owned by Anthony Weiner and Huma Abedin, and no warrant was necessary for that search because Weiner is cooperating with the FBI. \\nMany have been wondering why FBI Director James Comey would choose to make such a bold move just over a week until election day. Surely he had to know that this would have a dramatic impact on the election, and it is unlikely that he would have done so unless someone had already found something really big. In addition, Comey was reportedly eager to find an opportunity to redeem himself in the eyes of his peers at the FBI. The following is an excerpt from a Daily Mail article that was written by Ed Klein, the author of a recently released New York Times bestseller about the Clintons entitled “ Guilty As Sin “… \\n‘The atmosphere at the FBI has been toxic ever since Jim announced last July that he wouldn’t recommend an indictment against Hillary,’ said the source, a close friend who has known Comey for nearly two decades, shares family outings with him, and accompanies him to Catholic mass every week. \\n‘Some people, including department heads, stopped talking to Jim, and even ignored his greetings when they passed him in the hall,’ said the source. ‘They felt that he betrayed them and brought disgrace on the bureau by letting Hillary off with a slap on the wrist.’ \\nAccording to the source, Comey fretted over the problem for months and discussed it at great length with his wife, Patrice. \\nHe told his wife that he was depressed by the stack of resignation letters piling up on his desk from disaffected agents. The letters reminded him every day that morale in the FBI had hit rock bottom. \\nSo what happens next? \\nIn the most likely scenario, the FBI will not have time to complete the investigation and decide whether or not to charge Hillary Clinton before the election. This means that we would go into November 8th with this scandal hanging over the Clinton campaign, and that would seem to be very good news for Donald Trump. \\nHowever, it is possible that once the FBI starts searching through these emails that they could come to the conclusion very rapidly that charges against Clinton are warranted, and if that happens we could still see some sort of announcement before election day. \\nIn the unlikely event that does happen, we could actually see Hillary Clinton forced out of the race before November 8th. \\nOnce again, this appears to be very unlikely at this point, but it is still possible. \\nIf Clinton was forced to step aside, the Democrats would need to come up with a new nominee, and that process would take time. In an article later today on The Most Important News I will reveal who I believe that nominee would be. \\nIn such a scenario, the Democrats would desperately need time to get their act together, and so we could actually see Barack Obama attempt to delay or suspend the election . The legality of such a move is highly questionable, but Barack Obama has not allowed a little thing like the U.S. Constitution to stop him in the past. \\nThis week is going to be exceedingly interesting – that is for sure. \\nThe craziest election in modern American history just keeps getting crazier, and I have a feeling that even more twists and turns are ahead. \\nIt sure seems ironic that Anthony Weiner is playing such a central role this late in the story, and I can’t wait to see what is in store for the season finale. Post navigation',\n",
       " 'polarity': 0,\n",
       " '__index_level_0__': 4506}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, DataCollatorWithPadding, pipeline\n",
    "\n",
    "model = \"google-bert/bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4434/4434 [00:03<00:00, 1350.47 examples/s]\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 1527.95 examples/s]\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 1506.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "tokenized_train_dataloader = train_dataloader.map(preprocess_function, batched=True, batch_size=batch_size)\n",
    "tokenized_validation_dataloader = validation_dataloader.map(preprocess_function, batched=True, batch_size=batch_size)\n",
    "tokenized_test_dataloader = test_dataloader.map(preprocess_function, batched=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.77k/6.77k [00:00<?, ?B/s]\n",
      "Downloading builder script: 100%|██████████| 7.55k/7.55k [00:00<00:00, 7.55MB/s]\n",
      "Downloading builder script: 100%|██████████| 7.36k/7.36k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def evaluate(prediction_array):\n",
    "    logits, labels = prediction_array\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels)\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "[codecarbon INFO @ 01:18:02] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 01:18:02] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 01:18:02] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 01:18:02] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 01:18:02] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 01:18:03] CPU Model on constant consumption mode: AMD Ryzen 7 5800HS with Radeon Graphics\n",
      "[codecarbon INFO @ 01:18:03] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 01:18:03]   Platform system: Windows-11-10.0.22631-SP0\n",
      "[codecarbon INFO @ 01:18:03]   Python version: 3.12.0\n",
      "[codecarbon INFO @ 01:18:03]   CodeCarbon version: 2.3.3\n",
      "[codecarbon INFO @ 01:18:03]   Available RAM : 15.406 GB\n",
      "[codecarbon INFO @ 01:18:03]   CPU count: 16\n",
      "[codecarbon INFO @ 01:18:03]   CPU model: AMD Ryzen 7 5800HS with Radeon Graphics\n",
      "[codecarbon INFO @ 01:18:03]   GPU count: 1\n",
      "[codecarbon INFO @ 01:18:03]   GPU model: 1 x NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.00005\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"Transformer Model\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataloader,\n",
    "    eval_dataset=tokenized_validation_dataloader,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=evaluate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4170 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1127, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\alber\\AppData\\Roaming\\Python\\Python312\\site-packages\\executing\\executing.py\", line 163, in __init__\n",
      "    self.tree = ast.parse(self.text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "MemoryError\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 01:19:17] Energy consumed for RAM : 0.000024 kWh. RAM Power : 5.777113437652588 W\n",
      "[codecarbon INFO @ 01:19:17] Energy consumed for all GPUs : 0.000038 kWh. Total GPU Power : 9.200102397021807 W\n",
      "[codecarbon INFO @ 01:19:17] Energy consumed for all CPUs : 0.000073 kWh. Total CPU Power : 17.5 W\n",
      "[codecarbon INFO @ 01:19:17] 0.000135 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "# training_results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = trainer.evaluate(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
