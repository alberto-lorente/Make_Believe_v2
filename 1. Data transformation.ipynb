{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the original dataset\n",
    "text = pd.read_csv(r\"Datasets\\Celebrity Dataset\\Original dataset\\fakenews_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fake</td>\n",
       "      <td>Universities Agree with Trump on Immigration\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake</td>\n",
       "      <td>Chris Pratt responds to body shamers telling h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fake</td>\n",
       "      <td>\"Dancing With the Stars\": First couple won the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake</td>\n",
       "      <td>Brian Cox hosts scientist Postman Pat\\n\\nProfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fake</td>\n",
       "      <td>London Stock Exchange has dropped Merger with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>Jason Witten signs new four-year deal with Dal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>Google Maps can tell your friends exactly wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>Let there be light: German scientists test 'ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>Roger Federer beats Frances Tiafoe on return ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>Elon Musk creates Neuralink brain electrode f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Polarity                                               Text\n",
       "0       Fake  Universities Agree with Trump on Immigration\\n...\n",
       "1       Fake  Chris Pratt responds to body shamers telling h...\n",
       "2       Fake  \"Dancing With the Stars\": First couple won the...\n",
       "3       Fake  Brian Cox hosts scientist Postman Pat\\n\\nProfe...\n",
       "4       Fake  London Stock Exchange has dropped Merger with ...\n",
       "..       ...                                                ...\n",
       "475     TRUE  Jason Witten signs new four-year deal with Dal...\n",
       "476     TRUE  Google Maps can tell your friends exactly wher...\n",
       "477     TRUE  Let there be light: German scientists test 'ar...\n",
       "478     TRUE   Roger Federer beats Frances Tiafoe on return ...\n",
       "479     TRUE   Elon Musk creates Neuralink brain electrode f...\n",
       "\n",
       "[480 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"TRUE\", \"True\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from the vectorization performed with he TCT, we'll look at polarity and subjectivity scores just in case there are major differences between the two classes, as it is usual in fake news detection.\n",
    "\n",
    "For the subjectivity score I will use Textblob and for the polarity scores I will use VADER as it gives a more granular insight into the sentiment in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = SentimentIntensityAnalyzer()\n",
    "\n",
    "text[\"Overall_Sentiment\"] = text[\"Text\"].apply(lambda row:sent.polarity_scores(row)[\"compound\"])\n",
    "text[\"Positive_Sentiment\"] = text[\"Text\"].apply(lambda row:sent.polarity_scores(row)[\"neg\"])\n",
    "text[\"Negative_Sentiment\"] = text[\"Text\"].apply(lambda row:sent.polarity_scores(row)[\"pos\"])\n",
    "text[\"Neutral_Sentiment\"] = text[\"Text\"].apply(lambda row:sent.polarity_scores(row)[\"neu\"])\n",
    "\n",
    "text[\"Subjectivity\"] = text[\"Text\"].apply(lambda row:TextBlob(row).sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Text</th>\n",
       "      <th>Overall_Sentiment</th>\n",
       "      <th>Positive_Sentiment</th>\n",
       "      <th>Negative_Sentiment</th>\n",
       "      <th>Neutral_Sentiment</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fake</td>\n",
       "      <td>Universities Agree with Trump on Immigration\\n...</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.332143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fake</td>\n",
       "      <td>Chris Pratt responds to body shamers telling h...</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.513112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fake</td>\n",
       "      <td>\"Dancing With the Stars\": First couple won the...</td>\n",
       "      <td>-0.2944</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.397129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake</td>\n",
       "      <td>Brian Cox hosts scientist Postman Pat\\n\\nProfe...</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.497222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fake</td>\n",
       "      <td>London Stock Exchange has dropped Merger with ...</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.454167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>True</td>\n",
       "      <td>Jason Witten signs new four-year deal with Dal...</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.428052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>True</td>\n",
       "      <td>Google Maps can tell your friends exactly wher...</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.395543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>True</td>\n",
       "      <td>Let there be light: German scientists test 'ar...</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.620455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>True</td>\n",
       "      <td>Roger Federer beats Frances Tiafoe on return ...</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.473939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>True</td>\n",
       "      <td>Elon Musk creates Neuralink brain electrode f...</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.461250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Polarity                                               Text  \\\n",
       "0       Fake  Universities Agree with Trump on Immigration\\n...   \n",
       "1       Fake  Chris Pratt responds to body shamers telling h...   \n",
       "2       Fake  \"Dancing With the Stars\": First couple won the...   \n",
       "3       Fake  Brian Cox hosts scientist Postman Pat\\n\\nProfe...   \n",
       "4       Fake  London Stock Exchange has dropped Merger with ...   \n",
       "..       ...                                                ...   \n",
       "475     True  Jason Witten signs new four-year deal with Dal...   \n",
       "476     True  Google Maps can tell your friends exactly wher...   \n",
       "477     True  Let there be light: German scientists test 'ar...   \n",
       "478     True   Roger Federer beats Frances Tiafoe on return ...   \n",
       "479     True   Elon Musk creates Neuralink brain electrode f...   \n",
       "\n",
       "     Overall_Sentiment  Positive_Sentiment  Negative_Sentiment  \\\n",
       "0               0.7783               0.033               0.109   \n",
       "1               0.7763               0.045               0.106   \n",
       "2              -0.2944               0.150               0.123   \n",
       "3               0.6486               0.000               0.032   \n",
       "4               0.9531               0.000               0.145   \n",
       "..                 ...                 ...                 ...   \n",
       "475             0.6705               0.017               0.069   \n",
       "476             0.9590               0.024               0.180   \n",
       "477             0.7964               0.000               0.090   \n",
       "478             0.9532               0.089               0.175   \n",
       "479             0.8225               0.000               0.106   \n",
       "\n",
       "     Neutral_Sentiment  Subjectivity  \n",
       "0                0.858      0.332143  \n",
       "1                0.849      0.513112  \n",
       "2                0.726      0.397129  \n",
       "3                0.968      0.497222  \n",
       "4                0.855      0.454167  \n",
       "..                 ...           ...  \n",
       "475              0.914      0.428052  \n",
       "476              0.796      0.395543  \n",
       "477              0.910      0.620455  \n",
       "478              0.736      0.473939  \n",
       "479              0.894      0.461250  \n",
       "\n",
       "[480 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data after the vectorization with the TCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B-Z1NgAM1CzE"
   },
   "outputs": [],
   "source": [
    "fake_df = pd.read_table(r'Datasets\\Celebrity Dataset\\Data Transformed\\fake.tsv', delimiter = '\\t')\n",
    "true_df = pd.read_table(r'Datasets\\Celebrity Dataset\\Data Transformed\\true.tsv', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"FAKE \\n \", fake_df.describe())\n",
    "# print(\"TRUE \\n \", true_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"text_key\" in fake_df.columns:\n",
    "    fake_df= fake_df.drop(labels=\"text_key\", axis = 1) # categorical value will trigger an error when normalizing so we take this column out\n",
    "    \n",
    "if \"text_key\" in true_df.columns:   \n",
    "    true_df = true_df.drop(labels=\"text_key\", axis = 1)\n",
    "    \n",
    "# if \"id\" in fake_df.columns: \n",
    "#     fake_df= fake_df.drop(labels=\"id\", axis = 1) \n",
    "\n",
    "# if \"id\" in true_df.columns: \n",
    "#     true_df = true_df.drop(labels=\"id\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "#checking the columns are the same to verify we have the same features for both dfs\n",
    "\n",
    "print(fake_df.columns == true_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the polarity column\n",
    "\n",
    "true_df[\"Polarity\"] = \"True\"\n",
    "fake_df[\"Polarity\"] = \"Fake\"\n",
    "\n",
    "#adding the DFs\n",
    "\n",
    "dfs = [fake_df, true_df]\n",
    "true_and_fake = pd.concat(dfs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_and_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DESPC</th>\n",
       "      <th>DESSC</th>\n",
       "      <th>DESWC</th>\n",
       "      <th>DESPL</th>\n",
       "      <th>DESPLd</th>\n",
       "      <th>DESPLw</th>\n",
       "      <th>DESSL</th>\n",
       "      <th>DESSLd</th>\n",
       "      <th>DESWLsy</th>\n",
       "      <th>...</th>\n",
       "      <th>WORD_PROPERTY_WRDPOLc</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPn</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPv</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPnv</th>\n",
       "      <th>WORD_PROPERTY_AOA</th>\n",
       "      <th>WORD_PROPERTY_AOA_MAX</th>\n",
       "      <th>WORD_PROPERTY_CONCRETENESS</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE_MIN</th>\n",
       "      <th>WORD_SET_INCIDENCE_C4_COMMON_WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.908163</td>\n",
       "      <td>...</td>\n",
       "      <td>8.266667</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>6.196173</td>\n",
       "      <td>12.630000</td>\n",
       "      <td>2.523704</td>\n",
       "      <td>2.316489</td>\n",
       "      <td>2.316489</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>13.535139</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>7.216667</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>3.161290</td>\n",
       "      <td>4.892755</td>\n",
       "      <td>11.810000</td>\n",
       "      <td>2.688333</td>\n",
       "      <td>2.317815</td>\n",
       "      <td>2.317815</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.933147</td>\n",
       "      <td>1.348485</td>\n",
       "      <td>...</td>\n",
       "      <td>7.113924</td>\n",
       "      <td>6.433333</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>4.446809</td>\n",
       "      <td>5.274480</td>\n",
       "      <td>11.699415</td>\n",
       "      <td>2.743217</td>\n",
       "      <td>2.313201</td>\n",
       "      <td>2.313201</td>\n",
       "      <td>0.174242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>10.653638</td>\n",
       "      <td>1.342857</td>\n",
       "      <td>...</td>\n",
       "      <td>6.701299</td>\n",
       "      <td>6.423077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>4.589744</td>\n",
       "      <td>5.012647</td>\n",
       "      <td>10.280000</td>\n",
       "      <td>2.840101</td>\n",
       "      <td>2.274963</td>\n",
       "      <td>2.274963</td>\n",
       "      <td>0.135714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>6.827814</td>\n",
       "      <td>1.306569</td>\n",
       "      <td>...</td>\n",
       "      <td>8.724638</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>4.309524</td>\n",
       "      <td>5.335149</td>\n",
       "      <td>14.720000</td>\n",
       "      <td>2.391863</td>\n",
       "      <td>2.289871</td>\n",
       "      <td>2.289871</td>\n",
       "      <td>0.175182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>9.449868</td>\n",
       "      <td>1.394161</td>\n",
       "      <td>...</td>\n",
       "      <td>9.041096</td>\n",
       "      <td>6.230769</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>4.775000</td>\n",
       "      <td>5.534232</td>\n",
       "      <td>11.786635</td>\n",
       "      <td>2.695100</td>\n",
       "      <td>2.292326</td>\n",
       "      <td>2.292326</td>\n",
       "      <td>0.167883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>237</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>32.750000</td>\n",
       "      <td>20.172176</td>\n",
       "      <td>1.244275</td>\n",
       "      <td>...</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>6.043478</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>3.825000</td>\n",
       "      <td>5.002707</td>\n",
       "      <td>11.940000</td>\n",
       "      <td>2.602743</td>\n",
       "      <td>2.319229</td>\n",
       "      <td>2.319229</td>\n",
       "      <td>0.129771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>238</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.468085</td>\n",
       "      <td>...</td>\n",
       "      <td>8.830508</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>4.794118</td>\n",
       "      <td>5.695342</td>\n",
       "      <td>14.620000</td>\n",
       "      <td>2.855897</td>\n",
       "      <td>2.310864</td>\n",
       "      <td>2.310864</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>10.650509</td>\n",
       "      <td>1.366834</td>\n",
       "      <td>...</td>\n",
       "      <td>9.404040</td>\n",
       "      <td>6.178571</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>4.998212</td>\n",
       "      <td>12.890000</td>\n",
       "      <td>2.628047</td>\n",
       "      <td>2.312582</td>\n",
       "      <td>2.312582</td>\n",
       "      <td>0.090452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>240</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>13.160547</td>\n",
       "      <td>1.520833</td>\n",
       "      <td>...</td>\n",
       "      <td>7.406780</td>\n",
       "      <td>6.695652</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>6.449658</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>2.629231</td>\n",
       "      <td>2.299808</td>\n",
       "      <td>2.299808</td>\n",
       "      <td>0.114583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  DESPC  DESSC  DESWC     DESPL    DESPLd     DESPLw      DESSL  \\\n",
       "0      1    5.0    2.0   98.0  1.000000  0.000000  48.500000  49.000000   \n",
       "1      2    3.0    5.0  126.0  2.500000  2.121320  60.500000  25.200000   \n",
       "2      3    3.0    6.0  132.0  3.000000  2.828427  65.000000  22.000000   \n",
       "3      4    3.0    5.0  140.0  2.500000  2.121320  69.500000  28.000000   \n",
       "4      5    3.0    7.0  137.0  3.500000  3.535534  65.000000  19.571429   \n",
       "..   ...    ...    ...    ...       ...       ...        ...        ...   \n",
       "235  236    3.0    5.0  137.0  2.500000  2.121320  66.500000  27.400000   \n",
       "236  237    9.0    4.0  131.0  0.800000  0.447214  25.400000  32.750000   \n",
       "237  238    5.0    2.0   94.0  0.666667  0.577350  30.666667  47.000000   \n",
       "238  239    3.0   10.0  199.0  5.000000  4.242641  92.500000  19.900000   \n",
       "239  240    3.0    5.0   96.0  2.500000  0.707107  45.500000  19.200000   \n",
       "\n",
       "        DESSLd   DESWLsy  ...  WORD_PROPERTY_WRDPOLc  WORD_PROPERTY_WRDHYPn  \\\n",
       "0     1.414214  1.908163  ...               8.266667               5.857143   \n",
       "1    13.535139  1.285714  ...               7.216667               5.916667   \n",
       "2    11.933147  1.348485  ...               7.113924               6.433333   \n",
       "3    10.653638  1.342857  ...               6.701299               6.423077   \n",
       "4     6.827814  1.306569  ...               8.724638               6.818182   \n",
       "..         ...       ...  ...                    ...                    ...   \n",
       "235   9.449868  1.394161  ...               9.041096               6.230769   \n",
       "236  20.172176  1.244275  ...               9.916667               6.043478   \n",
       "237   1.414214  1.468085  ...               8.830508               6.545455   \n",
       "238  10.650509  1.366834  ...               9.404040               6.178571   \n",
       "239  13.160547  1.520833  ...               7.406780               6.695652   \n",
       "\n",
       "     WORD_PROPERTY_WRDHYPv  WORD_PROPERTY_WRDHYPnv  WORD_PROPERTY_AOA  \\\n",
       "0                 1.250000                4.181818           6.196173   \n",
       "1                 1.421053                3.161290           4.892755   \n",
       "2                 0.941176                4.446809           5.274480   \n",
       "3                 0.923077                4.589744           5.012647   \n",
       "4                 1.550000                4.309524           5.335149   \n",
       "..                     ...                     ...                ...   \n",
       "235               2.071429                4.775000           5.534232   \n",
       "236               0.823529                3.825000           5.002707   \n",
       "237               1.583333                4.794118           5.695342   \n",
       "238               0.588235                4.066667           4.998212   \n",
       "239               1.333333                4.578947           6.449658   \n",
       "\n",
       "     WORD_PROPERTY_AOA_MAX  WORD_PROPERTY_CONCRETENESS  \\\n",
       "0                12.630000                    2.523704   \n",
       "1                11.810000                    2.688333   \n",
       "2                11.699415                    2.743217   \n",
       "3                10.280000                    2.840101   \n",
       "4                14.720000                    2.391863   \n",
       "..                     ...                         ...   \n",
       "235              11.786635                    2.695100   \n",
       "236              11.940000                    2.602743   \n",
       "237              14.620000                    2.855897   \n",
       "238              12.890000                    2.628047   \n",
       "239              13.110000                    2.629231   \n",
       "\n",
       "     WORD_PROPERTY_PREVALENCE  WORD_PROPERTY_PREVALENCE_MIN  \\\n",
       "0                    2.316489                      2.316489   \n",
       "1                    2.317815                      2.317815   \n",
       "2                    2.313201                      2.313201   \n",
       "3                    2.274963                      2.274963   \n",
       "4                    2.289871                      2.289871   \n",
       "..                        ...                           ...   \n",
       "235                  2.292326                      2.292326   \n",
       "236                  2.319229                      2.319229   \n",
       "237                  2.310864                      2.310864   \n",
       "238                  2.312582                      2.312582   \n",
       "239                  2.299808                      2.299808   \n",
       "\n",
       "     WORD_SET_INCIDENCE_C4_COMMON_WORDS  \n",
       "0                              0.204082  \n",
       "1                              0.111111  \n",
       "2                              0.174242  \n",
       "3                              0.135714  \n",
       "4                              0.175182  \n",
       "..                                  ...  \n",
       "235                            0.167883  \n",
       "236                            0.129771  \n",
       "237                            0.106383  \n",
       "238                            0.090452  \n",
       "239                            0.114583  \n",
       "\n",
       "[480 rows x 63 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to index the columns excluding the polarity \n",
    "true_and_fake.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "p4rL6yjV4WU-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:472: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "c:\\Users\\alber\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:489: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the data \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols = list(true_and_fake.columns[:-1])\n",
    "\n",
    "true_and_fake[cols] = scaler.fit_transform(true_and_fake[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = true_and_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DESPC</th>\n",
       "      <th>DESSC</th>\n",
       "      <th>DESWC</th>\n",
       "      <th>DESPL</th>\n",
       "      <th>DESPLd</th>\n",
       "      <th>DESPLw</th>\n",
       "      <th>DESSL</th>\n",
       "      <th>DESSLd</th>\n",
       "      <th>DESWLsy</th>\n",
       "      <th>...</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPn</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPv</th>\n",
       "      <th>WORD_PROPERTY_WRDHYPnv</th>\n",
       "      <th>WORD_PROPERTY_AOA</th>\n",
       "      <th>WORD_PROPERTY_AOA_MAX</th>\n",
       "      <th>WORD_PROPERTY_CONCRETENESS</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE_MIN</th>\n",
       "      <th>WORD_SET_INCIDENCE_C4_COMMON_WORDS</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151143</td>\n",
       "      <td>0.682139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404405</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.363359</td>\n",
       "      <td>0.536598</td>\n",
       "      <td>0.396186</td>\n",
       "      <td>0.393986</td>\n",
       "      <td>0.674648</td>\n",
       "      <td>0.674648</td>\n",
       "      <td>0.685198</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.201948</td>\n",
       "      <td>0.249849</td>\n",
       "      <td>0.248429</td>\n",
       "      <td>0.109532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420646</td>\n",
       "      <td>0.278947</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>0.057090</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>0.612986</td>\n",
       "      <td>0.682585</td>\n",
       "      <td>0.682585</td>\n",
       "      <td>0.252618</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.220999</td>\n",
       "      <td>0.191726</td>\n",
       "      <td>0.215594</td>\n",
       "      <td>0.199330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561619</td>\n",
       "      <td>0.150980</td>\n",
       "      <td>0.439013</td>\n",
       "      <td>0.197521</td>\n",
       "      <td>0.297608</td>\n",
       "      <td>0.685996</td>\n",
       "      <td>0.654967</td>\n",
       "      <td>0.654967</td>\n",
       "      <td>0.546360</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.240051</td>\n",
       "      <td>0.300706</td>\n",
       "      <td>0.189370</td>\n",
       "      <td>0.191279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558820</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.479820</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>0.147246</td>\n",
       "      <td>0.814876</td>\n",
       "      <td>0.426085</td>\n",
       "      <td>0.426085</td>\n",
       "      <td>0.367094</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.220999</td>\n",
       "      <td>0.147614</td>\n",
       "      <td>0.110956</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666625</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.399818</td>\n",
       "      <td>0.219840</td>\n",
       "      <td>0.617585</td>\n",
       "      <td>0.218604</td>\n",
       "      <td>0.515320</td>\n",
       "      <td>0.515320</td>\n",
       "      <td>0.550734</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.983264</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.227350</td>\n",
       "      <td>0.289808</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.264674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506349</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.293080</td>\n",
       "      <td>0.306847</td>\n",
       "      <td>0.621988</td>\n",
       "      <td>0.530017</td>\n",
       "      <td>0.530017</td>\n",
       "      <td>0.516772</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.053345</td>\n",
       "      <td>0.386983</td>\n",
       "      <td>0.384460</td>\n",
       "      <td>0.050249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455246</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>0.261489</td>\n",
       "      <td>0.097540</td>\n",
       "      <td>0.323093</td>\n",
       "      <td>0.499129</td>\n",
       "      <td>0.691053</td>\n",
       "      <td>0.691053</td>\n",
       "      <td>0.339440</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.991632</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.075642</td>\n",
       "      <td>0.645812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592211</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.538168</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>0.606992</td>\n",
       "      <td>0.835890</td>\n",
       "      <td>0.640981</td>\n",
       "      <td>0.640981</td>\n",
       "      <td>0.230619</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.337426</td>\n",
       "      <td>0.153582</td>\n",
       "      <td>0.189306</td>\n",
       "      <td>0.225581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492107</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.330483</td>\n",
       "      <td>0.095886</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.532790</td>\n",
       "      <td>0.651265</td>\n",
       "      <td>0.651265</td>\n",
       "      <td>0.156495</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.138442</td>\n",
       "      <td>0.140868</td>\n",
       "      <td>0.240751</td>\n",
       "      <td>0.445890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633193</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.476738</td>\n",
       "      <td>0.629851</td>\n",
       "      <td>0.447034</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.574802</td>\n",
       "      <td>0.574802</td>\n",
       "      <td>0.268774</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     DESPC     DESSC     DESWC     DESPL    DESPLd    DESPLw  \\\n",
       "0    0.000000  0.444444  0.000000  0.146154  0.027027  0.000000  0.151143   \n",
       "1    0.004184  0.222222  0.176471  0.253846  0.148649  0.176471  0.201948   \n",
       "2    0.008368  0.222222  0.235294  0.276923  0.189189  0.235294  0.220999   \n",
       "3    0.012552  0.222222  0.176471  0.307692  0.148649  0.176471  0.240051   \n",
       "4    0.016736  0.222222  0.294118  0.296154  0.229730  0.294118  0.220999   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "235  0.983264  0.222222  0.176471  0.296154  0.148649  0.176471  0.227350   \n",
       "236  0.987448  0.888889  0.117647  0.273077  0.010811  0.037203  0.053345   \n",
       "237  0.991632  0.444444  0.000000  0.130769  0.000000  0.048029  0.075642   \n",
       "238  0.995816  0.222222  0.470588  0.534615  0.351351  0.352941  0.337426   \n",
       "239  1.000000  0.222222  0.176471  0.138462  0.148649  0.058824  0.138442   \n",
       "\n",
       "        DESSL    DESSLd   DESWLsy  ...  WORD_PROPERTY_WRDHYPn  \\\n",
       "0    0.682139  0.000000  1.000000  ...               0.404405   \n",
       "1    0.249849  0.248429  0.109532  ...               0.420646   \n",
       "2    0.191726  0.215594  0.199330  ...               0.561619   \n",
       "3    0.300706  0.189370  0.191279  ...               0.558820   \n",
       "4    0.147614  0.110956  0.139367  ...               0.666625   \n",
       "..        ...       ...       ...  ...                    ...   \n",
       "235  0.289808  0.164698  0.264674  ...               0.506349   \n",
       "236  0.386983  0.384460  0.050249  ...               0.455246   \n",
       "237  0.645812  0.000000  0.370429  ...               0.592211   \n",
       "238  0.153582  0.189306  0.225581  ...               0.492107   \n",
       "239  0.140868  0.240751  0.445890  ...               0.633193   \n",
       "\n",
       "     WORD_PROPERTY_WRDHYPv  WORD_PROPERTY_WRDHYPnv  WORD_PROPERTY_AOA  \\\n",
       "0                 0.233333                0.363359           0.536598   \n",
       "1                 0.278947                0.072002           0.057090   \n",
       "2                 0.150980                0.439013           0.197521   \n",
       "3                 0.146154                0.479820           0.101196   \n",
       "4                 0.313333                0.399818           0.219840   \n",
       "..                     ...                     ...                ...   \n",
       "235               0.452381                0.532710           0.293080   \n",
       "236               0.119608                0.261489           0.097540   \n",
       "237               0.322222                0.538168           0.352350   \n",
       "238               0.056863                0.330483           0.095886   \n",
       "239               0.255556                0.476738           0.629851   \n",
       "\n",
       "     WORD_PROPERTY_AOA_MAX  WORD_PROPERTY_CONCRETENESS  \\\n",
       "0                 0.396186                    0.393986   \n",
       "1                 0.309322                    0.612986   \n",
       "2                 0.297608                    0.685996   \n",
       "3                 0.147246                    0.814876   \n",
       "4                 0.617585                    0.218604   \n",
       "..                     ...                         ...   \n",
       "235               0.306847                    0.621988   \n",
       "236               0.323093                    0.499129   \n",
       "237               0.606992                    0.835890   \n",
       "238               0.423729                    0.532790   \n",
       "239               0.447034                    0.534365   \n",
       "\n",
       "     WORD_PROPERTY_PREVALENCE  WORD_PROPERTY_PREVALENCE_MIN  \\\n",
       "0                    0.674648                      0.674648   \n",
       "1                    0.682585                      0.682585   \n",
       "2                    0.654967                      0.654967   \n",
       "3                    0.426085                      0.426085   \n",
       "4                    0.515320                      0.515320   \n",
       "..                        ...                           ...   \n",
       "235                  0.530017                      0.530017   \n",
       "236                  0.691053                      0.691053   \n",
       "237                  0.640981                      0.640981   \n",
       "238                  0.651265                      0.651265   \n",
       "239                  0.574802                      0.574802   \n",
       "\n",
       "     WORD_SET_INCIDENCE_C4_COMMON_WORDS  Polarity  \n",
       "0                              0.685198      Fake  \n",
       "1                              0.252618      Fake  \n",
       "2                              0.546360      Fake  \n",
       "3                              0.367094      Fake  \n",
       "4                              0.550734      Fake  \n",
       "..                                  ...       ...  \n",
       "235                            0.516772      True  \n",
       "236                            0.339440      True  \n",
       "237                            0.230619      True  \n",
       "238                            0.156495      True  \n",
       "239                            0.268774      True  \n",
       "\n",
       "[480 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.drop([\"id\"], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the vectorized TCT df and the Sentiment df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESPC', 'DESSC', 'DESWC', 'DESPL', 'DESPLd', 'DESPLw', 'DESSL',\n",
       "       'DESSLd', 'DESWLsy', 'DESWLsyd', 'DESWLlt', 'DESWLltd', 'LDTTRc',\n",
       "       'LDTTRa', 'LDMTLD', 'LDHDD', 'SYNLE', 'SYNNP', 'SYNMEDpos', 'SYNMEDwrd',\n",
       "       'SYNMEDlem', 'SYNSTRUTa', 'SYNSTRUTt', 'RDFRE', 'READFKGL',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_ALHPA', 'TOKEN_ATTRIBUTE_RATIO_DIGIT',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_PUNCT', 'TOKEN_ATTRIBUTE_RATIO_URL',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_EMAIL', 'WORD_SET_INCIDENCE_WRDPRP1s',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP1p', 'WORD_SET_INCIDENCE_WRDPRP2',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP3s', 'WORD_SET_INCIDENCE_WRDPRP3p',\n",
       "       'WORD_SET_INCIDENCE_CNCCaus', 'WORD_SET_INCIDENCE_CNCLogic',\n",
       "       'WORD_SET_INCIDENCE_CNCTemp', 'WORD_SET_INCIDENCE_CNCAdd',\n",
       "       'WORD_SET_INCIDENCE_CNCPos', 'WORD_SET_INCIDENCE_CNCNeg',\n",
       "       'WORD_PROPERTY_WRDNOUN', 'WORD_PROPERTY_WRDVERB',\n",
       "       'WORD_PROPERTY_WRDADJ', 'WORD_PROPERTY_WRDADV', 'WORD_PROPERTY_WRDFRQc',\n",
       "       'WORD_PROPERTY_WRDFRQa', 'WORD_PROPERTY_WRDFRQmc',\n",
       "       'WORD_PROPERTY_WRDFAMc', 'WORD_PROPERTY_WRDCNCc',\n",
       "       'WORD_PROPERTY_WRDIMGc', 'WORD_PROPERTY_WRDMEAc',\n",
       "       'WORD_PROPERTY_WRDPOLc', 'WORD_PROPERTY_WRDHYPn',\n",
       "       'WORD_PROPERTY_WRDHYPv', 'WORD_PROPERTY_WRDHYPnv', 'WORD_PROPERTY_AOA',\n",
       "       'WORD_PROPERTY_AOA_MAX', 'WORD_PROPERTY_CONCRETENESS',\n",
       "       'WORD_PROPERTY_PREVALENCE', 'WORD_PROPERTY_PREVALENCE_MIN',\n",
       "       'WORD_SET_INCIDENCE_C4_COMMON_WORDS', 'Polarity', 'Polarity', 'Text',\n",
       "       'Overall_Sentiment', 'Positive_Sentiment', 'Negative_Sentiment',\n",
       "       'Neutral_Sentiment', 'Subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = df_scaled.reset_index(drop=True)\n",
    "df_scaled = pd.concat([df_scaled, text], axis =1)\n",
    "df_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESPC', 'DESSC', 'DESWC', 'DESPL', 'DESPLd', 'DESPLw', 'DESSL',\n",
       "       'DESSLd', 'DESWLsy', 'DESWLsyd', 'DESWLlt', 'DESWLltd', 'LDTTRc',\n",
       "       'LDTTRa', 'LDMTLD', 'LDHDD', 'SYNLE', 'SYNNP', 'SYNMEDpos', 'SYNMEDwrd',\n",
       "       'SYNMEDlem', 'SYNSTRUTa', 'SYNSTRUTt', 'RDFRE', 'READFKGL',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_ALHPA', 'TOKEN_ATTRIBUTE_RATIO_DIGIT',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_PUNCT', 'TOKEN_ATTRIBUTE_RATIO_URL',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_EMAIL', 'WORD_SET_INCIDENCE_WRDPRP1s',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP1p', 'WORD_SET_INCIDENCE_WRDPRP2',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP3s', 'WORD_SET_INCIDENCE_WRDPRP3p',\n",
       "       'WORD_SET_INCIDENCE_CNCCaus', 'WORD_SET_INCIDENCE_CNCLogic',\n",
       "       'WORD_SET_INCIDENCE_CNCTemp', 'WORD_SET_INCIDENCE_CNCAdd',\n",
       "       'WORD_SET_INCIDENCE_CNCPos', 'WORD_SET_INCIDENCE_CNCNeg',\n",
       "       'WORD_PROPERTY_WRDNOUN', 'WORD_PROPERTY_WRDVERB',\n",
       "       'WORD_PROPERTY_WRDADJ', 'WORD_PROPERTY_WRDADV', 'WORD_PROPERTY_WRDFRQc',\n",
       "       'WORD_PROPERTY_WRDFRQa', 'WORD_PROPERTY_WRDFRQmc',\n",
       "       'WORD_PROPERTY_WRDFAMc', 'WORD_PROPERTY_WRDCNCc',\n",
       "       'WORD_PROPERTY_WRDIMGc', 'WORD_PROPERTY_WRDMEAc',\n",
       "       'WORD_PROPERTY_WRDPOLc', 'WORD_PROPERTY_WRDHYPn',\n",
       "       'WORD_PROPERTY_WRDHYPv', 'WORD_PROPERTY_WRDHYPnv', 'WORD_PROPERTY_AOA',\n",
       "       'WORD_PROPERTY_AOA_MAX', 'WORD_PROPERTY_CONCRETENESS',\n",
       "       'WORD_PROPERTY_PREVALENCE', 'WORD_SET_INCIDENCE_C4_COMMON_WORDS',\n",
       "       'Polarity', 'Overall_Sentiment', 'Positive_Sentiment',\n",
       "       'Negative_Sentiment', 'Neutral_Sentiment', 'Subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = df_scaled.T.drop_duplicates().T #removing the duplicate Polarity column\n",
    "del df_scaled[\"Text\"]\n",
    "\n",
    "df_scaled.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SYNSTRUTt                      480\n",
       "DESPLd                          30\n",
       "DESPC                            0\n",
       "WORD_PROPERTY_WRDADJ             0\n",
       "WORD_PROPERTY_WRDFAMc            0\n",
       "                              ... \n",
       "TOKEN_ATTRIBUTE_RATIO_EMAIL      0\n",
       "WORD_SET_INCIDENCE_WRDPRP1s      0\n",
       "WORD_SET_INCIDENCE_WRDPRP1p      0\n",
       "WORD_SET_INCIDENCE_WRDPRP2       0\n",
       "Subjectivity                     0\n",
       "Length: 67, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.isna().sum().sort_values(ascending=False)       \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the SYNSTRUTt feature is empty for all the rows so we will just delete that column. I also noticed later down the line that the feature TOKEN_ATTRIBUTE_RATIO_EMAIL only has 0 as a value, which was causing problems, so I will be dropping that feature as well.\n",
    "\n",
    "\n",
    "As far as the DesPld feature, we will remove the rows that have empty values since there are not that many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNSTRUTt\n",
      "TOKEN_ATTRIBUTE_RATIO_EMAIL\n"
     ]
    }
   ],
   "source": [
    "for col in df_scaled:\n",
    "    if len(list(df_scaled[col].unique())) < 2:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.drop(labels=[\"SYNSTRUTt\"], axis=1)\n",
    "df_scaled = df_scaled.drop(labels=[\"TOKEN_ATTRIBUTE_RATIO_EMAIL\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df_scaled.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "d4dltSsaSU9j",
    "outputId": "fd3af9a1-89d6-45c0-b827-36beb50dabb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 64\n",
      "Number of texts: 450\n"
     ]
    }
   ],
   "source": [
    "#Number of features and text\n",
    "\n",
    "print(\"Number of features:\", df_scaled.drop(labels=[\"Polarity\"], axis=1).shape[1])\n",
    "print(\"Number of texts:\", df_scaled.drop(labels=[\"Polarity\"], axis=1).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESPC</th>\n",
       "      <th>DESSC</th>\n",
       "      <th>DESWC</th>\n",
       "      <th>DESPL</th>\n",
       "      <th>DESPLd</th>\n",
       "      <th>DESPLw</th>\n",
       "      <th>DESSL</th>\n",
       "      <th>DESSLd</th>\n",
       "      <th>DESWLsy</th>\n",
       "      <th>DESWLsyd</th>\n",
       "      <th>...</th>\n",
       "      <th>WORD_PROPERTY_AOA_MAX</th>\n",
       "      <th>WORD_PROPERTY_CONCRETENESS</th>\n",
       "      <th>WORD_PROPERTY_PREVALENCE</th>\n",
       "      <th>WORD_SET_INCIDENCE_C4_COMMON_WORDS</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Overall_Sentiment</th>\n",
       "      <th>Positive_Sentiment</th>\n",
       "      <th>Negative_Sentiment</th>\n",
       "      <th>Neutral_Sentiment</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151143</td>\n",
       "      <td>0.682139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396186</td>\n",
       "      <td>0.393986</td>\n",
       "      <td>0.674648</td>\n",
       "      <td>0.685198</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.332143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.201948</td>\n",
       "      <td>0.249849</td>\n",
       "      <td>0.248429</td>\n",
       "      <td>0.109532</td>\n",
       "      <td>0.116088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309322</td>\n",
       "      <td>0.612986</td>\n",
       "      <td>0.682585</td>\n",
       "      <td>0.252618</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.513112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.220999</td>\n",
       "      <td>0.191726</td>\n",
       "      <td>0.215594</td>\n",
       "      <td>0.19933</td>\n",
       "      <td>0.134906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297608</td>\n",
       "      <td>0.685996</td>\n",
       "      <td>0.654967</td>\n",
       "      <td>0.54636</td>\n",
       "      <td>Fake</td>\n",
       "      <td>-0.2944</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.397129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.240051</td>\n",
       "      <td>0.300706</td>\n",
       "      <td>0.18937</td>\n",
       "      <td>0.191279</td>\n",
       "      <td>0.119235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147246</td>\n",
       "      <td>0.814876</td>\n",
       "      <td>0.426085</td>\n",
       "      <td>0.367094</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.497222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.22973</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.220999</td>\n",
       "      <td>0.147614</td>\n",
       "      <td>0.110956</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>0.084885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617585</td>\n",
       "      <td>0.218604</td>\n",
       "      <td>0.51532</td>\n",
       "      <td>0.550734</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.454167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.22735</td>\n",
       "      <td>0.289808</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>0.264674</td>\n",
       "      <td>0.203276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306847</td>\n",
       "      <td>0.621988</td>\n",
       "      <td>0.530017</td>\n",
       "      <td>0.516772</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.428052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.273077</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.053345</td>\n",
       "      <td>0.386983</td>\n",
       "      <td>0.38446</td>\n",
       "      <td>0.050249</td>\n",
       "      <td>0.047174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323093</td>\n",
       "      <td>0.499129</td>\n",
       "      <td>0.691053</td>\n",
       "      <td>0.33944</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.395543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.075642</td>\n",
       "      <td>0.645812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370429</td>\n",
       "      <td>0.251662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606992</td>\n",
       "      <td>0.83589</td>\n",
       "      <td>0.640981</td>\n",
       "      <td>0.230619</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.620455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.534615</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.337426</td>\n",
       "      <td>0.153582</td>\n",
       "      <td>0.189306</td>\n",
       "      <td>0.225581</td>\n",
       "      <td>0.206593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.53279</td>\n",
       "      <td>0.651265</td>\n",
       "      <td>0.156495</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.473939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.138462</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.138442</td>\n",
       "      <td>0.140868</td>\n",
       "      <td>0.240751</td>\n",
       "      <td>0.44589</td>\n",
       "      <td>0.305984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447034</td>\n",
       "      <td>0.534365</td>\n",
       "      <td>0.574802</td>\n",
       "      <td>0.268774</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.46125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DESPC     DESSC     DESWC     DESPL    DESPLd    DESPLw     DESSL  \\\n",
       "0    0.444444       0.0  0.146154  0.027027       0.0  0.151143  0.682139   \n",
       "1    0.222222  0.176471  0.253846  0.148649  0.176471  0.201948  0.249849   \n",
       "2    0.222222  0.235294  0.276923  0.189189  0.235294  0.220999  0.191726   \n",
       "3    0.222222  0.176471  0.307692  0.148649  0.176471  0.240051  0.300706   \n",
       "4    0.222222  0.294118  0.296154   0.22973  0.294118  0.220999  0.147614   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "475  0.222222  0.176471  0.296154  0.148649  0.176471   0.22735  0.289808   \n",
       "476  0.888889  0.117647  0.273077  0.010811  0.037203  0.053345  0.386983   \n",
       "477  0.444444       0.0  0.130769       0.0  0.048029  0.075642  0.645812   \n",
       "478  0.222222  0.470588  0.534615  0.351351  0.352941  0.337426  0.153582   \n",
       "479  0.222222  0.176471  0.138462  0.148649  0.058824  0.138442  0.140868   \n",
       "\n",
       "       DESSLd   DESWLsy  DESWLsyd  ... WORD_PROPERTY_AOA_MAX  \\\n",
       "0         0.0       1.0  0.563762  ...              0.396186   \n",
       "1    0.248429  0.109532  0.116088  ...              0.309322   \n",
       "2    0.215594   0.19933  0.134906  ...              0.297608   \n",
       "3     0.18937  0.191279  0.119235  ...              0.147246   \n",
       "4    0.110956  0.139367  0.084885  ...              0.617585   \n",
       "..        ...       ...       ...  ...                   ...   \n",
       "475  0.164698  0.264674  0.203276  ...              0.306847   \n",
       "476   0.38446  0.050249  0.047174  ...              0.323093   \n",
       "477       0.0  0.370429  0.251662  ...              0.606992   \n",
       "478  0.189306  0.225581  0.206593  ...              0.423729   \n",
       "479  0.240751   0.44589  0.305984  ...              0.447034   \n",
       "\n",
       "    WORD_PROPERTY_CONCRETENESS WORD_PROPERTY_PREVALENCE  \\\n",
       "0                     0.393986                 0.674648   \n",
       "1                     0.612986                 0.682585   \n",
       "2                     0.685996                 0.654967   \n",
       "3                     0.814876                 0.426085   \n",
       "4                     0.218604                  0.51532   \n",
       "..                         ...                      ...   \n",
       "475                   0.621988                 0.530017   \n",
       "476                   0.499129                 0.691053   \n",
       "477                    0.83589                 0.640981   \n",
       "478                    0.53279                 0.651265   \n",
       "479                   0.534365                 0.574802   \n",
       "\n",
       "    WORD_SET_INCIDENCE_C4_COMMON_WORDS Polarity Overall_Sentiment  \\\n",
       "0                             0.685198     Fake            0.7783   \n",
       "1                             0.252618     Fake            0.7763   \n",
       "2                              0.54636     Fake           -0.2944   \n",
       "3                             0.367094     Fake            0.6486   \n",
       "4                             0.550734     Fake            0.9531   \n",
       "..                                 ...      ...               ...   \n",
       "475                           0.516772     True            0.6705   \n",
       "476                            0.33944     True             0.959   \n",
       "477                           0.230619     True            0.7964   \n",
       "478                           0.156495     True            0.9532   \n",
       "479                           0.268774     True            0.8225   \n",
       "\n",
       "    Positive_Sentiment Negative_Sentiment Neutral_Sentiment Subjectivity  \n",
       "0                0.033              0.109             0.858     0.332143  \n",
       "1                0.045              0.106             0.849     0.513112  \n",
       "2                 0.15              0.123             0.726     0.397129  \n",
       "3                  0.0              0.032             0.968     0.497222  \n",
       "4                  0.0              0.145             0.855     0.454167  \n",
       "..                 ...                ...               ...          ...  \n",
       "475              0.017              0.069             0.914     0.428052  \n",
       "476              0.024               0.18             0.796     0.395543  \n",
       "477                0.0               0.09              0.91     0.620455  \n",
       "478              0.089              0.175             0.736     0.473939  \n",
       "479                0.0              0.106             0.894      0.46125  \n",
       "\n",
       "[450 rows x 65 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESPC', 'DESSC', 'DESWC', 'DESPL', 'DESPLd', 'DESPLw', 'DESSL',\n",
       "       'DESSLd', 'DESWLsy', 'DESWLsyd', 'DESWLlt', 'DESWLltd', 'LDTTRc',\n",
       "       'LDTTRa', 'LDMTLD', 'LDHDD', 'SYNLE', 'SYNNP', 'SYNMEDpos', 'SYNMEDwrd',\n",
       "       'SYNMEDlem', 'SYNSTRUTa', 'RDFRE', 'READFKGL',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_ALHPA', 'TOKEN_ATTRIBUTE_RATIO_DIGIT',\n",
       "       'TOKEN_ATTRIBUTE_RATIO_PUNCT', 'TOKEN_ATTRIBUTE_RATIO_URL',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP1s', 'WORD_SET_INCIDENCE_WRDPRP1p',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP2', 'WORD_SET_INCIDENCE_WRDPRP3s',\n",
       "       'WORD_SET_INCIDENCE_WRDPRP3p', 'WORD_SET_INCIDENCE_CNCCaus',\n",
       "       'WORD_SET_INCIDENCE_CNCLogic', 'WORD_SET_INCIDENCE_CNCTemp',\n",
       "       'WORD_SET_INCIDENCE_CNCAdd', 'WORD_SET_INCIDENCE_CNCPos',\n",
       "       'WORD_SET_INCIDENCE_CNCNeg', 'WORD_PROPERTY_WRDNOUN',\n",
       "       'WORD_PROPERTY_WRDVERB', 'WORD_PROPERTY_WRDADJ', 'WORD_PROPERTY_WRDADV',\n",
       "       'WORD_PROPERTY_WRDFRQc', 'WORD_PROPERTY_WRDFRQa',\n",
       "       'WORD_PROPERTY_WRDFRQmc', 'WORD_PROPERTY_WRDFAMc',\n",
       "       'WORD_PROPERTY_WRDCNCc', 'WORD_PROPERTY_WRDIMGc',\n",
       "       'WORD_PROPERTY_WRDMEAc', 'WORD_PROPERTY_WRDPOLc',\n",
       "       'WORD_PROPERTY_WRDHYPn', 'WORD_PROPERTY_WRDHYPv',\n",
       "       'WORD_PROPERTY_WRDHYPnv', 'WORD_PROPERTY_AOA', 'WORD_PROPERTY_AOA_MAX',\n",
       "       'WORD_PROPERTY_CONCRETENESS', 'WORD_PROPERTY_PREVALENCE',\n",
       "       'WORD_SET_INCIDENCE_C4_COMMON_WORDS', 'Polarity', 'Overall_Sentiment',\n",
       "       'Positive_Sentiment', 'Negative_Sentiment', 'Neutral_Sentiment',\n",
       "       'Subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the transformed dataset we will use for the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "Nhi7BqAqettq",
    "outputId": "f5a91da9-85f6-461a-a568-8d15923f0d37"
   },
   "outputs": [],
   "source": [
    "df_scaled.to_csv(r\"Datasets\\Celebrity Dataset\\Celebrity_dataset_transformed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
